{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMjhwg2S3EFKEjPwja3/rg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manusree1324/NLP-LAB/blob/main/NLP_22_08_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGj_MJddIfrK",
        "outputId": "b141245b-90f6-4222-eb4b-d99208761982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['Unnamed: 0', 'description_x', 'description_y', 'ticker_x', 'ticker_y',\n",
            "       'same_security'],\n",
            "      dtype='object')\n",
            "\n",
            "First 5 entries in description_x column:\n",
            "0                       first trust dow jones internet\n",
            "1                  schwab intl large company index etf\n",
            "2                         vanguard small cap index adm\n",
            "3    duke energy corp new com new isin #us4 sedol #...\n",
            "4                                     visa inc class a\n",
            "Name: description_x, dtype: object\n",
            "\n",
            "After removing nulls: (2142, 6)\n",
            "\n",
            "Sentence 1: first trust dow jones internet\n",
            "Tokens with POS:\n",
            "first           -> PROPN\n",
            "trust           -> PROPN\n",
            "dow             -> PROPN\n",
            "jones           -> PROPN\n",
            "internet        -> PROPN\n",
            "\n",
            "Nouns: []\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 2: schwab intl large company index etf\n",
            "Tokens with POS:\n",
            "schwab          -> PROPN\n",
            "intl            -> PROPN\n",
            "large           -> ADJ\n",
            "company         -> NOUN\n",
            "index           -> NOUN\n",
            "etf             -> NOUN\n",
            "\n",
            "Nouns: ['company', 'index', 'etf']\n",
            "Verbs: []\n",
            "Adjectives: ['large']\n",
            "\n",
            "Sentence 3: vanguard small cap index adm\n",
            "Tokens with POS:\n",
            "vanguard        -> PROPN\n",
            "small           -> PROPN\n",
            "cap             -> PROPN\n",
            "index           -> NOUN\n",
            "adm             -> PROPN\n",
            "\n",
            "Nouns: ['index']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 4: duke energy corp new com new isin #us4 sedol #b7jzsk0\n",
            "Tokens with POS:\n",
            "duke            -> PROPN\n",
            "energy          -> PROPN\n",
            "corp            -> PROPN\n",
            "new             -> PROPN\n",
            "com             -> NOUN\n",
            "new             -> ADJ\n",
            "isin            -> NOUN\n",
            "#               -> SYM\n",
            "us4             -> PROPN\n",
            "sedol           -> NOUN\n",
            "#               -> SYM\n",
            "b7jzsk0         -> PROPN\n",
            "\n",
            "Nouns: ['com', 'isin', 'sedol']\n",
            "Verbs: []\n",
            "Adjectives: ['new']\n",
            "\n",
            "Sentence 5: visa inc class a\n",
            "Tokens with POS:\n",
            "visa            -> PROPN\n",
            "inc             -> PROPN\n",
            "class           -> PROPN\n",
            "a               -> PROPN\n",
            "\n",
            "Nouns: []\n",
            "Verbs: []\n",
            "Adjectives: []\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Dataset Loading\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset (after downloading from Kaggle)\n",
        "df = pd.read_csv(\"train.csv\")   # file name from Kaggle dataset\n",
        "\n",
        "# Inspect structure\n",
        "print(\"Columns:\", df.columns)\n",
        "print(\"\\nFirst 5 entries in description_x column:\")\n",
        "print(df['description_x'].head())\n",
        "\n",
        "# Drop null values\n",
        "df = df.dropna(subset=['description_x'])\n",
        "print(\"\\nAfter removing nulls:\", df.shape)\n",
        "\n",
        "\n",
        "# Task 2: POS Tagging with spaCy\n",
        "import spacy\n",
        "\n",
        "# Load small English model (run: python -m spacy download en_core_web_sm if missing)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Take first 5 sentences\n",
        "sentences = df['description_x'].head().tolist()\n",
        "\n",
        "for i, sentence in enumerate(sentences, 1):\n",
        "    print(f\"\\nSentence {i}: {sentence}\")\n",
        "    doc = nlp(sentence)\n",
        "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
        "    adjs  = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
        "\n",
        "    print(\"Tokens with POS:\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text:<15} -> {token.pos_}\")\n",
        "\n",
        "    print(\"\\nNouns:\", nouns)\n",
        "    print(\"Verbs:\", verbs)\n",
        "    print(\"Adjectives:\", adjs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "texts = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "# Regex patterns\n",
        "phone_pattern = r\"\\+?\\d[\\d\\s\\-]{8,}\\d\"   # matches phone numbers\n",
        "email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "url_pattern   = r\"http[s]?://\\S+\"\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove phones, emails, urls\n",
        "    text = re.sub(phone_pattern, \" \", text)\n",
        "    text = re.sub(email_pattern, \" \", text)\n",
        "    text = re.sub(url_pattern, \" \", text)\n",
        "\n",
        "    # Remove special characters (except words and spaces)\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)\n",
        "\n",
        "    # Normalize spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "for t in texts:\n",
        "    print(\"\\nOriginal:\", t)\n",
        "    print(\"Cleaned :\", clean_text(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJPoSsGzI-G3",
        "outputId": "f38a4bea-609f-4ba7-8915-a9a3a8d7cb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original: My phone number is 1234567890 and my email is test@domain.com\n",
            "Cleaned : My phone number is and my email is\n",
            "\n",
            "Original: Visit https://example.com for more info!!!\n",
            "Cleaned : Visit for more info\n",
            "\n",
            "Original: HELLO!!! This is SOOOOO exciting :))\n",
            "Cleaned : HELLO This is SOOOOO exciting\n",
            "\n",
            "Original: Contact us at info@company.org or call +91 98765-43210\n",
            "Cleaned : Contact us at or call\n",
            "\n",
            "Original: Python's regex is very useful!!!  #Coding #Fun\n",
            "Cleaned : Python s regex is very useful Coding Fun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "texts = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "# Regex patterns\n",
        "phone_pattern = r\"\\+?\\d[\\d\\s\\-]{8,}\\d\"   # matches phone numbers\n",
        "email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
        "url_pattern   = r\"http[s]?://\\S+\"\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove phones, emails, urls\n",
        "    text = re.sub(phone_pattern, \" \", text)\n",
        "    text = re.sub(email_pattern, \" \", text)\n",
        "    text = re.sub(url_pattern, \" \", text)\n",
        "\n",
        "    # Remove special characters (except words and spaces)\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)\n",
        "\n",
        "    # Normalize spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "for t in texts:\n",
        "    print(\"\\nOriginal:\", t)\n",
        "    print(\"Cleaned :\", clean_text(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAVx2Hd1JF7Z",
        "outputId": "ec3158ce-f30c-4192-e8bb-a0fba0941f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original: My phone number is 1234567890 and my email is test@domain.com\n",
            "Cleaned : My phone number is and my email is\n",
            "\n",
            "Original: Visit https://example.com for more info!!!\n",
            "Cleaned : Visit for more info\n",
            "\n",
            "Original: HELLO!!! This is SOOOOO exciting :))\n",
            "Cleaned : HELLO This is SOOOOO exciting\n",
            "\n",
            "Original: Contact us at info@company.org or call +91 98765-43210\n",
            "Cleaned : Contact us at or call\n",
            "\n",
            "Original: Python's regex is very useful!!!  #Coding #Fun\n",
            "Cleaned : Python s regex is very useful Coding Fun\n"
          ]
        }
      ]
    }
  ]
}